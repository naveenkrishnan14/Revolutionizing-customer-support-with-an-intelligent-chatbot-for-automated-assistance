from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt')

# Tokenizing text
data['tokens'] = data['text'].apply(word_tokenize)
